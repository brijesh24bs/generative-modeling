{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe980ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:30.143630Z",
     "iopub.status.busy": "2024-03-08T15:54:30.142940Z",
     "iopub.status.idle": "2024-03-08T15:54:30.152960Z",
     "shell.execute_reply": "2024-03-08T15:54:30.152240Z"
    },
    "papermill": {
     "duration": 0.018553,
     "end_time": "2024-03-08T15:54:30.154796",
     "exception": false,
     "start_time": "2024-03-08T15:54:30.136243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#celeba dataset\n",
    "img_dir = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\n",
    "attributes_file = \"/kaggle/input/celeba-dataset/list_attr_celeba.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fa0c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:30.165782Z",
     "iopub.status.busy": "2024-03-08T15:54:30.165495Z",
     "iopub.status.idle": "2024-03-08T15:54:33.895833Z",
     "shell.execute_reply": "2024-03-08T15:54:33.894896Z"
    },
    "papermill": {
     "duration": 3.7381,
     "end_time": "2024-03-08T15:54:33.897992",
     "exception": false,
     "start_time": "2024-03-08T15:54:30.159892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working/output': No such file or directory\r\n",
      "rm: cannot remove '/kaggle/working/checkpoint': No such file or directory\r\n",
      "rm: cannot remove '/kaggle/working/logs': No such file or directory\r\n",
      "rm: cannot remove '/kaggle/working/state.db': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/output\n",
    "!rm -r /kaggle/working/checkpoint\n",
    "!rm -r /kaggle/working/logs\n",
    "!rm /kaggle/working/state.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a08076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:33.910352Z",
     "iopub.status.busy": "2024-03-08T15:54:33.910025Z",
     "iopub.status.idle": "2024-03-08T15:54:41.082540Z",
     "shell.execute_reply": "2024-03-08T15:54:41.081490Z"
    },
    "papermill": {
     "duration": 7.181699,
     "end_time": "2024-03-08T15:54:41.085091",
     "exception": false,
     "start_time": "2024-03-08T15:54:33.903392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26adf75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:41.098154Z",
     "iopub.status.busy": "2024-03-08T15:54:41.097529Z",
     "iopub.status.idle": "2024-03-08T15:54:41.191799Z",
     "shell.execute_reply": "2024-03-08T15:54:41.190897Z"
    },
    "papermill": {
     "duration": 0.102887,
     "end_time": "2024-03-08T15:54:41.193931",
     "exception": false,
     "start_time": "2024-03-08T15:54:41.091044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image = read_image('/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/000001.jpg')\n",
    "transform = transforms.Resize((224, 224)),\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "image = transform(image)\n",
    "# print(image.size())\n",
    "\n",
    "# image = np.transpose(image, (1, 2, 0))\n",
    "# plt.imshow(image)  # Assuming the image is grayscale\n",
    "# plt.axis('off')  # Turn off axis\n",
    "# plt.show()\n",
    "# print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe44ac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:41.206869Z",
     "iopub.status.busy": "2024-03-08T15:54:41.206176Z",
     "iopub.status.idle": "2024-03-08T15:54:41.209975Z",
     "shell.execute_reply": "2024-03-08T15:54:41.209064Z"
    },
    "papermill": {
     "duration": 0.012037,
     "end_time": "2024-03-08T15:54:41.211764",
     "exception": false,
     "start_time": "2024-03-08T15:54:41.199727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(attributes_file)\n",
    "# data.dtypes\n",
    "# data.iloc[0].tolist()[1:]detach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e303708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:41.223787Z",
     "iopub.status.busy": "2024-03-08T15:54:41.223490Z",
     "iopub.status.idle": "2024-03-08T15:54:41.227788Z",
     "shell.execute_reply": "2024-03-08T15:54:41.227034Z"
    },
    "papermill": {
     "duration": 0.012523,
     "end_time": "2024-03-08T15:54:41.229658",
     "exception": false,
     "start_time": "2024-03-08T15:54:41.217135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 256\n",
    "NUM_FEATURES = 128\n",
    "Z_DIM = 200\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 10\n",
    "BETA = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63d5b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:41.241765Z",
     "iopub.status.busy": "2024-03-08T15:54:41.241485Z",
     "iopub.status.idle": "2024-03-08T15:54:42.432695Z",
     "shell.execute_reply": "2024-03-08T15:54:42.431898Z"
    },
    "papermill": {
     "duration": 1.199711,
     "end_time": "2024-03-08T15:54:42.434870",
     "exception": false,
     "start_time": "2024-03-08T15:54:41.235159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "class CELEBADataset(Dataset):\n",
    "    def __init__(self, img_dir, attr_file=None, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.attr = pd.read_csv(attr_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.attr)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, \"{:06d}.jpg\".format(idx+1))\n",
    "        image = read_image(img_path)\n",
    "#         label = self.attr.iloc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = CELEBADataset(img_dir,attributes_file,transform=transform)\n",
    "# subset_dataset = Subset(dataset, range(256))\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bc6cd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.447457Z",
     "iopub.status.busy": "2024-03-08T15:54:42.447197Z",
     "iopub.status.idle": "2024-03-08T15:54:42.451820Z",
     "shell.execute_reply": "2024-03-08T15:54:42.450978Z"
    },
    "papermill": {
     "duration": 0.012958,
     "end_time": "2024-03-08T15:54:42.453653",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.440695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define the sampling layer\n",
    "class Sampling(nn.Module):\n",
    "    def forward(self, z_mean, z_log_var):\n",
    "        epsilon = torch.randn_like(z_log_var)\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef393f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.466008Z",
     "iopub.status.busy": "2024-03-08T15:54:42.465644Z",
     "iopub.status.idle": "2024-03-08T15:54:42.475333Z",
     "shell.execute_reply": "2024-03-08T15:54:42.474467Z"
    },
    "papermill": {
     "duration": 0.017851,
     "end_time": "2024-03-08T15:54:42.477132",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.459281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #batch normalization layer\n",
    "        self.bn = nn.BatchNorm2d(NUM_FEATURES)\n",
    "        \n",
    "        #convolutional layers\n",
    "        self.conv1 = nn.Conv2d(CHANNELS, NUM_FEATURES, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(NUM_FEATURES, NUM_FEATURES, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(NUM_FEATURES, NUM_FEATURES, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(NUM_FEATURES, NUM_FEATURES, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #flatten the last layer's output\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc_mean = nn.Linear(NUM_FEATURES * 8 * 8 , Z_DIM)\n",
    "        self.fc_log_var = nn.Linear(NUM_FEATURES * 8 * 8, Z_DIM)\n",
    "        self.sampling = Sampling()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn(self.conv2(x)))\n",
    "        x = F.leaky_relu(self.bn(self.conv3(x)))\n",
    "        x = F.leaky_relu(self.bn(self.conv4(x)))\n",
    "        \n",
    "        x = self.flatten(x) ##128x8192\n",
    "        \n",
    "        z_mean = self.fc_mean(x)\n",
    "        z_log_var = self.fc_log_var(x)\n",
    "        z = self.sampling(z_mean, z_log_var)\n",
    "        return z_mean, z_log_var, z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4e93910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.489240Z",
     "iopub.status.busy": "2024-03-08T15:54:42.488976Z",
     "iopub.status.idle": "2024-03-08T15:54:42.492374Z",
     "shell.execute_reply": "2024-03-08T15:54:42.491639Z"
    },
    "papermill": {
     "duration": 0.011408,
     "end_time": "2024-03-08T15:54:42.494100",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.482692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enc = Encoder()\n",
    "# y = enc(b)\n",
    "# print(y[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483d3014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.506322Z",
     "iopub.status.busy": "2024-03-08T15:54:42.506064Z",
     "iopub.status.idle": "2024-03-08T15:54:42.515843Z",
     "shell.execute_reply": "2024-03-08T15:54:42.515013Z"
    },
    "papermill": {
     "duration": 0.018116,
     "end_time": "2024-03-08T15:54:42.517755",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.499639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#decoder\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(Z_DIM, NUM_FEATURES * 8 * 8)\n",
    "        self.bn1d = nn.BatchNorm1d(NUM_FEATURES * 8 * 8)\n",
    "        self.bn2d = nn.BatchNorm2d(NUM_FEATURES)\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose2d(NUM_FEATURES, NUM_FEATURES, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv2 = nn.ConvTranspose2d(NUM_FEATURES, NUM_FEATURES, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3 = nn.ConvTranspose2d(NUM_FEATURES, NUM_FEATURES, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv4 = nn.ConvTranspose2d(NUM_FEATURES, NUM_FEATURES, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv5 = nn.ConvTranspose2d(NUM_FEATURES, CHANNELS, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = F.leaky_relu(self.bn1d(x))\n",
    "\n",
    "        x = x.view(-1, NUM_FEATURES, 8, 8)\n",
    "        x = F.leaky_relu(self.bn2d(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2d(self.conv2(x)))\n",
    "        x = F.leaky_relu(self.bn2d(self.conv3(x)))\n",
    "        x = F.leaky_relu(self.bn2d(self.conv4(x)))\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17228f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.529995Z",
     "iopub.status.busy": "2024-03-08T15:54:42.529730Z",
     "iopub.status.idle": "2024-03-08T15:54:42.533274Z",
     "shell.execute_reply": "2024-03-08T15:54:42.532455Z"
    },
    "papermill": {
     "duration": 0.01184,
     "end_time": "2024-03-08T15:54:42.535219",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.523379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = Decoder()\n",
    "# x = model(y[2])\n",
    "# print(x.size())\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f33032d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.549250Z",
     "iopub.status.busy": "2024-03-08T15:54:42.548578Z",
     "iopub.status.idle": "2024-03-08T15:54:42.559314Z",
     "shell.execute_reply": "2024-03-08T15:54:42.558528Z"
    },
    "papermill": {
     "duration": 0.020139,
     "end_time": "2024-03-08T15:54:42.561187",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.541048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        self.total_loss_tracker = []\n",
    "        self.reconstruction_loss_tracker = []\n",
    "        self.kl_loss_tracker = []\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return z_mean, z_log_var, reconstruction\n",
    "\n",
    "    def train_step(self, data, optimizer, beta):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z_mean, z_log_var, reconstruction = self(data)\n",
    "        reconstruction_loss = F.mse_loss(data, reconstruction)\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1).mean()\n",
    "        total_loss = reconstruction_loss + beta * kl_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        self.total_loss_tracker.append(total_loss.item())\n",
    "        self.reconstruction_loss_tracker.append(reconstruction_loss.item())\n",
    "        self.kl_loss_tracker.append(kl_loss.item())\n",
    "        \n",
    "        return {\n",
    "            \"loss\": total_loss.item(),\n",
    "            \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "            \"kl_loss\": kl_loss.item(),\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        with torch.no_grad():\n",
    "            z_mean, z_log_var, reconstruction = self(data)\n",
    "            reconstruction_loss = F.mse_loss(data, reconstruction)\n",
    "            kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1).mean()\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        \n",
    "        return {\n",
    "            \"loss\": total_loss.item(),\n",
    "            \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "            \"kl_loss\": kl_loss.item(),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf368b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.573869Z",
     "iopub.status.busy": "2024-03-08T15:54:42.573610Z",
     "iopub.status.idle": "2024-03-08T15:54:42.641982Z",
     "shell.execute_reply": "2024-03-08T15:54:42.641299Z"
    },
    "papermill": {
     "duration": 0.077092,
     "end_time": "2024-03-08T15:54:42.644088",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.566996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "vae = VAE(encoder, decoder)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=LEARNING_RATE)\n",
    "beta = BETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1b9c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:42.656855Z",
     "iopub.status.busy": "2024-03-08T15:54:42.656567Z",
     "iopub.status.idle": "2024-03-08T15:54:52.711944Z",
     "shell.execute_reply": "2024-03-08T15:54:52.711149Z"
    },
    "papermill": {
     "duration": 10.0641,
     "end_time": "2024-03-08T15:54:52.714132",
     "exception": false,
     "start_time": "2024-03-08T15:54:42.650032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 15:54:44.830949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 15:54:44.831043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 15:54:44.959312: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#define the optimizer\n",
    "optimizer = optim.Adam(vae.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#model checkpoint\n",
    "checkpoint_dir = \"./checkpoint\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "#save checkpoint\n",
    "def save_checkpoint(epoch, model, optimizer):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "\n",
    "#tensorboard callback\n",
    "log_dir = \"./logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "\n",
    "#image generation callback\n",
    "class ImageGenerator:\n",
    "    def __init__(self, num_img, latent_dim, decoder, device):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.output_dir = \"./output\"\n",
    "    def __call__(self, epoch):\n",
    "        with torch.no_grad():\n",
    "            random_latent_vectors = torch.randn((self.num_img, self.latent_dim)).to(self.device)\n",
    "            generated_images = decoder(random_latent_vectors).cpu()*255\n",
    "            \n",
    "            #save images to local\n",
    "            for i in range(self.num_img):\n",
    "                os.makedirs(self.output_dir, exist_ok=True)\n",
    "                img = transforms.ToPILImage()(generated_images[i])\n",
    "                img.save(os.path.join(self.output_dir, f\"generated_img_{epoch:3d}_{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34d8d50d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T15:54:52.728461Z",
     "iopub.status.busy": "2024-03-08T15:54:52.727540Z",
     "iopub.status.idle": "2024-03-08T18:55:06.426990Z",
     "shell.execute_reply": "2024-03-08T18:55:06.425962Z"
    },
    "papermill": {
     "duration": 10813.721355,
     "end_time": "2024-03-08T18:55:06.441841",
     "exception": false,
     "start_time": "2024-03-08T15:54:52.720486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 1: Total Loss: 8.7103, Recon Loss: 0.0003, KL Loss: 0.0044\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 2: Total Loss: 0.0565, Recon Loss: 0.0003, KL Loss: 0.0000\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 3: Total Loss: 0.0447, Recon Loss: 0.0003, KL Loss: 0.0000\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 4: Total Loss: 0.0835, Recon Loss: 0.0003, KL Loss: 0.0000\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 5: Total Loss: 0.0565, Recon Loss: 0.0003, KL Loss: 0.0000\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 6: Total Loss: 15.1885, Recon Loss: 0.0003, KL Loss: 0.0076\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 7: Total Loss: 0.2032, Recon Loss: 0.0003, KL Loss: 0.0001\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 8: Total Loss: 0.0349, Recon Loss: 0.0003, KL Loss: 0.0000\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 9: Total Loss: 0.0145, Recon Loss: 0.0003, KL Loss: 0.0000\n",
      "Training batch: 0\n",
      "Training batch: 100\n",
      "Training batch: 200\n",
      "Training batch: 300\n",
      "Training batch: 400\n",
      "Training batch: 500\n",
      "Training batch: 600\n",
      "Training batch: 700\n",
      "Epoch 10: Total Loss: 0.0080, Recon Loss: 0.0003, KL Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "def train_vae(model, train_loader, optimizer, epochs, beta, device, callbacks=[]):\n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#         model = nn.DataParallel(model)    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        recon_loss = 0.0\n",
    "        kl_loss = 0.0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            if batch_idx%100 == 0:\n",
    "                print(f\"Training batch: {batch_idx}\")\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            results = model.train_step(data, optimizer, beta)\n",
    "            total_loss += results[\"loss\"]\n",
    "            recon_loss += results[\"reconstruction_loss\"]\n",
    "            kl_loss += results[\"kl_loss\"]\n",
    "        total_loss /= len(train_loader.dataset)\n",
    "        recon_loss /= len(train_loader.dataset)\n",
    "        kl_loss /= len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch}: Total Loss: {total_loss:.4f}, Recon Loss: {recon_loss:.4f}, KL Loss: {kl_loss:.4f}\")\n",
    "        writer.add_scalar(\"Loss/Total\", total_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Reconstruction\", recon_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/KL\", kl_loss, epoch)\n",
    "        for callback in callbacks:\n",
    "            if isinstance(callback, ImageGenerator):\n",
    "                callback(epoch)\n",
    "        save_checkpoint(epoch, model, optimizer)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_generator_callback = ImageGenerator(num_img=10, latent_dim=Z_DIM, decoder=decoder, device=device)\n",
    "train_vae(vae, dataloader, optimizer, EPOCHS, BETA, device, callbacks=[image_generator_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01caad09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T18:55:06.469273Z",
     "iopub.status.busy": "2024-03-08T18:55:06.468557Z",
     "iopub.status.idle": "2024-03-08T18:55:06.566112Z",
     "shell.execute_reply": "2024-03-08T18:55:06.565232Z"
    },
    "papermill": {
     "duration": 0.113416,
     "end_time": "2024-03-08T18:55:06.568078",
     "exception": false,
     "start_time": "2024-03-08T18:55:06.454662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9906eba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T18:55:06.595660Z",
     "iopub.status.busy": "2024-03-08T18:55:06.595397Z",
     "iopub.status.idle": "2024-03-08T18:55:07.613124Z",
     "shell.execute_reply": "2024-03-08T18:55:07.611848Z"
    },
    "papermill": {
     "duration": 1.033834,
     "end_time": "2024-03-08T18:55:07.615382",
     "exception": false,
     "start_time": "2024-03-08T18:55:06.581548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar  8 18:55:07 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   59C    P0              42W / 250W |    520MiB / 16384MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41bcea56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T18:55:07.645014Z",
     "iopub.status.busy": "2024-03-08T18:55:07.644282Z",
     "iopub.status.idle": "2024-03-08T18:55:08.616793Z",
     "shell.execute_reply": "2024-03-08T18:55:08.615802Z"
    },
    "papermill": {
     "duration": 0.989865,
     "end_time": "2024-03-08T18:55:08.619086",
     "exception": false,
     "start_time": "2024-03-08T18:55:07.629221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\r\n"
     ]
    }
   ],
   "source": [
    "!kill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95741c4",
   "metadata": {
    "papermill": {
     "duration": 0.013169,
     "end_time": "2024-03-08T18:55:08.646025",
     "exception": false,
     "start_time": "2024-03-08T18:55:08.632856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 29561,
     "sourceId": 37705,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10844.670302,
   "end_time": "2024-03-08T18:55:12.081104",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T15:54:27.410802",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
